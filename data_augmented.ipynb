{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Important is Reccurrence for Video Classification?\n",
    "## Introduction\n",
    "Human behavior such as standing, running and jumping can be used in crowd control, for safety regulations, and can be analysed (for instance, to quantify the performance of a soccer player in a given match). Accordingly, the classification of human actions is an important tool that can be deployed for many use cases and is an important goal in the area of computer vision. Human actions are not instantaneous and usually play out over a longer sequence of time (e.g., a couple of seconds). \n",
    "\n",
    "Prior research has found that videos (in particular short clips) can be classified well using single frame models (Karpathy et al., 2014). However, the authors suggested utilising recurrent neural networks (RNNs) as a potential improvement for video classification. \n",
    "\n",
    "The goal of the current study is to estimate whether RNNs can encode temporal information of videos well and thereby improve classification accuracy of human actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "We construct an image-encoder with a pretrained base and a trainable head (3 feed-forward layers for classification). This image-encoder can be used for predicting actions already, however, videos are sequences of images. Therefore, we speculate that a neural network that can account for temporal dependencies may improve performance. To this end, we extend the image encoder with a recurrent neural network that takes chunks of encoded images as input.\n",
    "\n",
    "Data set: ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-19T17:10:59.823428Z",
     "iopub.status.busy": "2024-12-19T17:10:59.823088Z",
     "iopub.status.idle": "2024-12-19T17:10:59.832057Z",
     "shell.execute_reply": "2024-12-19T17:10:59.830768Z",
     "shell.execute_reply.started": "2024-12-19T17:10:59.823392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:11:04.547260Z",
     "iopub.status.busy": "2024-12-19T17:11:04.546888Z",
     "iopub.status.idle": "2024-12-19T17:11:04.565781Z",
     "shell.execute_reply": "2024-12-19T17:11:04.564574Z",
     "shell.execute_reply.started": "2024-12-19T17:11:04.547230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:11:06.243647Z",
     "iopub.status.busy": "2024-12-19T17:11:06.243305Z",
     "iopub.status.idle": "2024-12-19T17:11:06.266426Z",
     "shell.execute_reply": "2024-12-19T17:11:06.265540Z",
     "shell.execute_reply.started": "2024-12-19T17:11:06.243622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Get all classes \n",
    "main_data_dir = '/kaggle/input/HMDB_dataset/'  # Path without the extra folders\n",
    "all_classes_names = os.listdir(main_data_dir)\n",
    "print(all_classes_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:11:08.361653Z",
     "iopub.status.busy": "2024-12-19T17:11:08.361327Z",
     "iopub.status.idle": "2024-12-19T17:11:11.865459Z",
     "shell.execute_reply": "2024-12-19T17:11:11.864320Z",
     "shell.execute_reply.started": "2024-12-19T17:11:08.361626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a Matplotlib figure\n",
    "fig = plt.figure(figsize = (30, 30))\n",
    "\n",
    "# Generate a random sample of images each time the cell runs\n",
    "random_range = random.sample(range(len(all_classes_names)), 20)\n",
    "\n",
    "# Iterating through all the random samples\n",
    "for counter, random_index in enumerate(random_range, 1):\n",
    " \n",
    "    # Getting Class Name using Random Index\n",
    "    selected_class_Name = all_classes_names[random_index]\n",
    " \n",
    "    # Getting a list of all the video files present in a Class Directory\n",
    "    video_files_names_list = os.listdir(f'{main_data_dir}{selected_class_Name}')\n",
    "\n",
    "    # Randomly selecting a video file\n",
    "    selected_video_file_name = random.choice(video_files_names_list)\n",
    " \n",
    "    # Reading the Video File Using the Video Capture\n",
    "    print(f'{main_data_dir}{selected_class_Name}/{selected_video_file_name}')\n",
    "    video_reader = cv2.VideoCapture(f'{main_data_dir}{selected_class_Name}/{selected_video_file_name}')\n",
    "\n",
    "    # Reading The First Frame of the Video File\n",
    "    _, bgr_frame = video_reader.read()\n",
    "    \n",
    "    # Closing the VideoCapture object and releasing all resources. \n",
    "    video_reader.release()\n",
    " \n",
    "    # Converting the BGR Frame to RGB Frame \n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    # Adding The Class Name Text on top of the Video Frame.\n",
    "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "     \n",
    "    # Assigning the Frame to a specific position of a subplot\n",
    "    plt.subplot(5, 4, counter)\n",
    "    plt.imshow(rgb_frame)\n",
    "    plt.axis('off') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:11:20.828466Z",
     "iopub.status.busy": "2024-12-19T17:11:20.828107Z",
     "iopub.status.idle": "2024-12-19T17:11:21.679827Z",
     "shell.execute_reply": "2024-12-19T17:11:21.678861Z",
     "shell.execute_reply.started": "2024-12-19T17:11:20.828434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Free RAM space\n",
    "plt.close(fig)\n",
    "fig.clf()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:11:23.510586Z",
     "iopub.status.busy": "2024-12-19T17:11:23.510271Z",
     "iopub.status.idle": "2024-12-19T17:11:23.516749Z",
     "shell.execute_reply": "2024-12-19T17:11:23.515573Z",
     "shell.execute_reply.started": "2024-12-19T17:11:23.510562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_classes_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:11:27.529076Z",
     "iopub.status.busy": "2024-12-19T17:11:27.528749Z",
     "iopub.status.idle": "2024-12-19T17:11:27.534036Z",
     "shell.execute_reply": "2024-12-19T17:11:27.532800Z",
     "shell.execute_reply.started": "2024-12-19T17:11:27.529051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_height, image_width = 128, 128\n",
    "max_images_per_train_class = 8000\n",
    "max_images_per_test_class = 4000\n",
    " \n",
    "classes_list = [\"shoot_gun\", \"shoot_ball\", \"kiss\", \"smoke\"]\n",
    " \n",
    "model_output_size = len(classes_list)\n",
    "num_classes = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:11:29.352774Z",
     "iopub.status.busy": "2024-12-19T17:11:29.352419Z",
     "iopub.status.idle": "2024-12-19T17:11:29.374875Z",
     "shell.execute_reply": "2024-12-19T17:11:29.374087Z",
     "shell.execute_reply.started": "2024-12-19T17:11:29.352745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define data augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"), \n",
    "    layers.RandomRotation(0.4),  \n",
    "    layers.RandomZoom(0.2), \n",
    "    layers.RandomContrast(0.2), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:11:31.562467Z",
     "iopub.status.busy": "2024-12-19T17:11:31.562064Z",
     "iopub.status.idle": "2024-12-19T17:15:17.224312Z",
     "shell.execute_reply": "2024-12-19T17:15:17.223121Z",
     "shell.execute_reply.started": "2024-12-19T17:11:31.562435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to extract frames from a video\n",
    "def frames_extraction(video_path):\n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while True:\n",
    "        success, frame = video_reader.read()\n",
    "        if not success:\n",
    "            break\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        normalized_frame = resized_frame / 255.0  # Normalize pixel values\n",
    "        frames_list.append(normalized_frame)\n",
    "\n",
    "    video_reader.release()\n",
    "    return frames_list\n",
    "\n",
    "# Function to load data for selected classes\n",
    "def create_dataset(main_data_dir, classes_list, max_images_per_class, ):\n",
    "    data_train, labels_train = [], []\n",
    "    data_test, labels_test = [], []\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        class_folder = os.path.join(main_data_dir, class_name)\n",
    "        video_files = os.listdir(class_folder)\n",
    "    \n",
    "        count = 0\n",
    "        for video_file in video_files:\n",
    "            video_path = os.path.join(class_folder, video_file)\n",
    "            frames = frames_extraction(video_path)\n",
    "            if frames:  # Ensure frames were extracted\n",
    "                rand_frame_ids = np.random.choice(len(frames), size=2, replace=False)\n",
    "            if \"training\" in video_file:\n",
    "                for id in rand_frame_ids:\n",
    "                    data_train.append(frames[id])  # Use the first frame (can use others too)\n",
    "                    labels_train.append(class_index)\n",
    "                    count += 1\n",
    "            else:\n",
    "                for id in rand_frame_ids:\n",
    "                    data_test.append(frames[id])  # Use the first frame (can use others too)\n",
    "                    labels_test.append(class_index)\n",
    "                    count += 1\n",
    "            if count >= max_images_per_class:\n",
    "                break\n",
    "\n",
    "    return np.array(data_train), np.array(data_test), np.array(labels_train), np.array(labels_test)\n",
    "# Create the dataset\n",
    "max_images_per_class = 200\n",
    "X_train, X_test, y_train, y_test = create_dataset(main_data_dir, all_classes_names, max_images_per_class)\n",
    "print(f\"Dataset size: {y_train.shape[0] + y_test.shape[0]}, Train: {y_train.shape}, Test: {y_test.shape}\")\n",
    "\n",
    "# batch and shuffle train data\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(y_train.shape[0]).batch(100)\n",
    "# split test data into training and validation\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(y_test.shape[0]).batch(100)\n",
    "test_ds, val_ds = tf.keras.utils.split_dataset(test_ds, left_size=0.5, right_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition (Auto-Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:16:52.797424Z",
     "iopub.status.busy": "2024-12-19T17:16:52.797017Z",
     "iopub.status.idle": "2024-12-19T17:16:53.217521Z",
     "shell.execute_reply": "2024-12-19T17:16:53.216753Z",
     "shell.execute_reply.started": "2024-12-19T17:16:52.797385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the VGG16 base model with an explicit input shape\n",
    "base = tf.keras.applications.VGG16(\n",
    "    include_top=False,  # Remove the fully connected layers\n",
    "    weights='imagenet',  # Use pretrained weights\n",
    "    input_shape=(image_height, image_width, 3)  # Explicitly define the input shape\n",
    ")\n",
    "\n",
    "# Freeze base model layers\n",
    "base.trainable = False\n",
    "for layer in base.layers[-4:]:  \n",
    "    layer.trainable = True\n",
    "base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:16:56.432874Z",
     "iopub.status.busy": "2024-12-19T17:16:56.432516Z",
     "iopub.status.idle": "2024-12-19T17:16:56.577396Z",
     "shell.execute_reply": "2024-12-19T17:16:56.576533Z",
     "shell.execute_reply.started": "2024-12-19T17:16:56.432848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build Model \n",
    "num_classes = len(all_classes_names)\n",
    "model = keras.Sequential([\n",
    "    data_augmentation,\n",
    "    base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# **Explicitly Build the Model by Passing Sample Input**\n",
    "# Generate a sample input with the correct shape\n",
    "sample_input = np.random.random((1, image_height, image_width, 3))  # Batch of 1\n",
    "model(sample_input)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the ImageEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:16:58.944877Z",
     "iopub.status.busy": "2024-12-19T17:16:58.944475Z",
     "iopub.status.idle": "2024-12-19T17:16:58.960425Z",
     "shell.execute_reply": "2024-12-19T17:16:58.959580Z",
     "shell.execute_reply.started": "2024-12-19T17:16:58.944841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:17:01.114935Z",
     "iopub.status.busy": "2024-12-19T17:17:01.114576Z",
     "iopub.status.idle": "2024-12-19T17:28:25.303652Z",
     "shell.execute_reply": "2024-12-19T17:28:25.302790Z",
     "shell.execute_reply.started": "2024-12-19T17:17:01.114907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_hist = model.fit(\n",
    "    train_ds,\n",
    "    epochs=30,\n",
    "    validation_data=val_ds,\n",
    "    callbacks= [keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, min_lr=1e-6, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:28:31.215948Z",
     "iopub.status.busy": "2024-12-19T17:28:31.215590Z",
     "iopub.status.idle": "2024-12-19T17:28:31.816288Z",
     "shell.execute_reply": "2024-12-19T17:28:31.815240Z",
     "shell.execute_reply.started": "2024-12-19T17:28:31.215921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_frame = pd.DataFrame(train_hist.history)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].plot(history_frame.index, history_frame['accuracy'], label='train')\n",
    "ax[0].plot(history_frame.index, history_frame['val_accuracy'], label='val')\n",
    "_ = ax[0].set_xlabel('Epoch')\n",
    "_ = ax[0].set_ylabel('Accuracy')\n",
    "_ = ax[0].legend(loc='lower right')\n",
    "_ = ax[0].set_title(\"Accuracy Curve\")\n",
    "\n",
    "ax[1].plot(history_frame.index, history_frame['loss'], label='train')\n",
    "ax[1].plot(history_frame.index, history_frame['val_loss'], label='val')\n",
    "_ = ax[1].set_xlabel('Epoch')\n",
    "_ = ax[1].set_ylabel('Loss')\n",
    "_ = ax[1].legend(loc='upper right')\n",
    "_ = ax[1].set_title(\"Loss Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:28:34.783383Z",
     "iopub.status.busy": "2024-12-19T17:28:34.783040Z",
     "iopub.status.idle": "2024-12-19T17:28:40.416176Z",
     "shell.execute_reply": "2024-12-19T17:28:40.415084Z",
     "shell.execute_reply.started": "2024-12-19T17:28:34.783356Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_dist = model.predict(X_test)\n",
    "y_pred = np.argmax(y_dist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:28:44.069293Z",
     "iopub.status.busy": "2024-12-19T17:28:44.068954Z",
     "iopub.status.idle": "2024-12-19T17:28:44.075530Z",
     "shell.execute_reply": "2024-12-19T17:28:44.074166Z",
     "shell.execute_reply.started": "2024-12-19T17:28:44.069267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "correct_pred = [pred==true for pred, true in zip(y_pred, y_test)]\n",
    "print(f\"Accuracy: {np.mean(y_pred==y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:29:11.167249Z",
     "iopub.status.busy": "2024-12-19T17:29:11.166871Z",
     "iopub.status.idle": "2024-12-19T17:29:15.553352Z",
     "shell.execute_reply": "2024-12-19T17:29:15.552216Z",
     "shell.execute_reply.started": "2024-12-19T17:29:11.167214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# visualize some false predictions\n",
    "false_ids = [i for i, correct in enumerate(correct_pred) if not correct]\n",
    "n_false_plotted = 5\n",
    "fig, ax = plt.subplots(5, 2, figsize=(8,20), width_ratios=[1, 2])\n",
    "for i, id in enumerate(np.random.choice(false_ids, n_false_plotted)):\n",
    "    img = X_test[id] * 255.\n",
    "    img = img.astype(np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ax[i,0].imshow(img)\n",
    "    ax[i,0].set_title(f\"Pred:{all_classes_names[y_pred[id]]} True: {all_classes_names[y_test[id]]}\")\n",
    "    ax[i,0].set_axis_off()\n",
    "    \n",
    "    ax[i,1].bar(range(51),y_dist[id])\n",
    "    ax[i,1].set_title(\"Probability Distribution\")\n",
    "    ax[i,1].set_xlabel(\"action\")\n",
    "    ax[i,1].set_ylabel(\"P(action|image)\")\n",
    "    ax[i,1].set_xticks(range(51), labels=[all_classes_names[i] for i in range(51)], rotation=90, fontsize=8)\n",
    "    ax[i,1].spines['top'].set_visible(False)\n",
    "    ax[i,1].spines['right'].set_visible(False)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:42:29.090531Z",
     "iopub.status.busy": "2024-12-19T17:42:29.090188Z",
     "iopub.status.idle": "2024-12-19T17:42:29.495637Z",
     "shell.execute_reply": "2024-12-19T17:42:29.494513Z",
     "shell.execute_reply.started": "2024-12-19T17:42:29.090506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model architecture as a JSON file\n",
    "model_json = model.to_json()\n",
    "with open(\"model_architecture.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the model weights with the correct file extension\n",
    "model.save_weights(\"img_enc_weights.weights.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., & Fei-Fei, L. (2014). Large-scale video classification with convolutional neural networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (pp. 1725-1732).\n",
    "\n",
    "#### Potential extra references:\n",
    "\n",
    "A. Ullah, J. Ahmad, K. Muhammad, M. Sajjad and S. W. Baik, \"Action Recognition in Video Sequences using Deep Bi-Directional LSTM With CNN Features,\" in IEEE Access, vol. 6, pp. 1155-1166, 2018, doi: 10.1109/ACCESS.2017.2778011.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2749140,
     "sourceId": 4750382,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
